{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "Annoy treemap or FAISS or other solutions. Given a dataset of tensors, returns a dictionary or database or treemap structure, something that is searchable for later. It would be nice to be able to diff this somehow, or make sure that it's up-to-date. Maybe keeping two copies is okay? One for backup and quick-searching, one for main search once it's indexed any new images. \n",
    "\n",
    "This executor `needs` both Encoder and Loader to send it the new and old vectors, respectively. So it needs to be preceded by some kind of **join_all** component that can makesure we're not missing new data before handing it over to the indexer. Hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_all(db, new_files, new_embeddings):\n",
    "    for i, file in enumerate(new_files):\n",
    "        path, slug = file\n",
    "        start = len(db)\n",
    "        index = i + start\n",
    "        db[slug] = {\n",
    "            'slug': slug,\n",
    "            'fpath': path,\n",
    "            'embed': new_embeddings[i],\n",
    "            'index': index\n",
    "        }\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And build treemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_treemap(db):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "    for v in db.values():\n",
    "        treemap.add_item(v['index'], v['embed'])\n",
    "\n",
    "    # Build the treemap, with 5 trees rn\n",
    "    treemap.build(5)\n",
    "\n",
    "    return(treemap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = build_treemap(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3698, 5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_n_items(), t.get_n_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_archives(root, treemap, db):\n",
    "    dbpath = root/'memery.pt'\n",
    "    if dbpath.exists():\n",
    "#         dbpath.rename(root/'memery-bak.pt')\n",
    "        dbpath.unlink()\n",
    "    torch.save(db, dbpath)\n",
    "    \n",
    "    treepath = root/'memery.ann'\n",
    "    if treepath.exists():\n",
    "#         treepath.rename(root/'memery-bak.ann')\n",
    "        treepath.unlink()\n",
    "    treemap.save(str(treepath))\n",
    "    \n",
    "    return(str(dbpath), str(treepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/mage/Pictures/memes/memery.pt', '/home/mage/Pictures/memes/memery.ann')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_archives(root, t, db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
