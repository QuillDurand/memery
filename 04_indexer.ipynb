{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "Given a dataset of tensors, returns a dictionary archive and a treemap structure (and saves them to disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joiner\n",
    "\n",
    "This executor `needs` both Encoder and Loader to send it the new and old vectors, respectively. So it needs to be preceded by the **join_all** component to make sure we're not missing new data before handing it over to the indexer -- or indexing old data that no longer exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_all(db, new_files, new_embeddings):\n",
    "    start = len(db)\n",
    "    for i, file in enumerate(new_files):\n",
    "        path, slug = file\n",
    "        index = i + start\n",
    "        db[slug] = {\n",
    "            'slug': slug,\n",
    "            'fpath': path,\n",
    "            'embed': new_embeddings[i],\n",
    "            'index': index\n",
    "        }\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from memery.loader import db_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_loader(root/'memery.pt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wholesome-Meme-3_1621298477',\n",
       " 'Wholesome-Meme-44_1621298480',\n",
       " 'Wholesome-Meme-69_1621298481',\n",
       " 'Wholesome-Meme-59_1621298480',\n",
       " 'Wholesome-Meme-68_1621298481']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o[0] for o in db.items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building treemap takes a long time. I don't think `annoy` uses the GPU at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_treemap(db):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "    for v in db.values():\n",
    "        treemap.add_item(v['index'], v['embed'])\n",
    "\n",
    "    # Build the treemap, with 5 trees rn\n",
    "    treemap.build(5)\n",
    "\n",
    "    return(treemap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = build_treemap(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_n_items(), t.get_n_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_archives(root, treemap, db):\n",
    "    dbpath = root/'memery.pt'\n",
    "    if dbpath.exists():\n",
    "#         dbpath.rename(root/'memery-bak.pt')\n",
    "        dbpath.unlink()\n",
    "    torch.save(db, dbpath)\n",
    "    \n",
    "    treepath = root/'memery.ann'\n",
    "    if treepath.exists():\n",
    "#         treepath.rename(root/'memery-bak.ann')\n",
    "        treepath.unlink()\n",
    "    treemap.save(str(treepath))\n",
    "    \n",
    "    return(str(dbpath), str(treepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/memery.pt', 'images/memery.ann')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_archives(root, t, db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
