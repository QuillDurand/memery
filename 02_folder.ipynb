{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import clip\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemeFolder:\n",
    "    \"\"\"Takes an image folder and a CLIP model and calculates the encodings for each image\"\"\"\n",
    "    \n",
    "    def __init__(self, folder_str, clip_model=\"ViT-B/32\", clear_cache=False):\n",
    "        self.clear_cache = clear_cache\n",
    "        self.path = Path(folder_str)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, self.preprocess = clip.load(clip_model, device=self.device)\n",
    "        self.logit_scale = self.model.logit_scale.exp()\n",
    "        \n",
    "        self.names, self.features = self.process_images(self.path)\n",
    "        \n",
    "    def process_images(self, path):\n",
    "        \"\"\"Calculate image encodings from folder. \n",
    "        TODO: Fix recursive loading to include self folder\n",
    "        \"\"\"\n",
    "        savefile = path/'memery.pt'\n",
    "        if self.clear_cache == True:\n",
    "            savefile.unlink() # remove savefile if need be\n",
    "        # load or generate the encodings üóúÔ∏è\n",
    "        # currently this just checks to see if there's a savefile, not if anything has changed since save time\n",
    "        if savefile.exists():\n",
    "            save_dict = torch.load(savefile)\n",
    "            image_names = [k for k in save_dict.keys()]\n",
    "            image_features = torch.stack([v for v in save_dict.values()]).to(self.device)\n",
    "        else:\n",
    "            image_features = torch.tensor(()).to(device)\n",
    "            with torch.no_grad():\n",
    "                imagefiles=torchvision.datasets.ImageFolder(root=path, transform=preprocess)\n",
    "                img_loader=torch.utils.data.DataLoader(imagefiles, batch_size=128, shuffle=False, num_workers=4)\n",
    "                for images, labels in tqdm(img_loader):\n",
    "                    batch_features = model.encode_image(images)\n",
    "                    image_features = torch.cat((image_features, batch_features)).to(self.device)\n",
    "\n",
    "            image_names = [Path(f[0]) for f in imagefiles.imgs]\n",
    "            self.save(image_names, image_features)\n",
    "                           \n",
    "        return(image_names, image_features)\n",
    "    \n",
    "    def save(self, filenames, enc_tensors):\n",
    "        \"\"\"Saves a dictionary of filenames and encoding tensors\"\"\"\n",
    "        save_dict = {str(k):v for k, v in zip(filenames, enc_tensors)}\n",
    "        torch.save(save_dict, self.savefile)\n",
    "    \n",
    "    def predict_from_text(self, query):\n",
    "        \"\"\"Tokenize the text query and compare to each image. Returns a sorted dictionary of names\n",
    "        and scores\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            text = clip.tokenize(query).to(self.device)\n",
    "            text_features = self.model.encode_text(text)\n",
    "\n",
    "            # normalize features\n",
    "            self.features = self.features / self.features.norm(dim=-1, keepdim=True)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # cosine similarity as logits\n",
    "            logits_per_image = self.logit_scale * self.features @ text_features.float().t()\n",
    "\n",
    "        scores = {self.names[i]: logit for i, logit in enumerate(logits_per_image)}\n",
    "        top_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "        return(top_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = MemeFolder('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = small.predict_from_text('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/memes/wgglo1jpy4l61.jpg', tensor([27.2811], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
