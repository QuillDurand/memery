{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# memery\n",
    "\n",
    "> Use human language to search your image folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![meme about having too many memes](images/E2GoeMyWEAAkcLz.jpeg)\n",
    "\n",
    "The problem: you have a huge folder of images. Memes, screenshots, datasets, product photos, inspo albums, anything. You know that somewhere in that folder is the exact image you want, but you can't remember the filename or what day you saved it. There's nothing you can do but scroll through the folder, skimming hundreds of thumbnails, hoping you don't accidentally miss it, and that you'll recognize it when you do see it. \n",
    "\n",
    "Humans do this amazingly well. But even with computers, local image search is still a manual effort - you're still sorting through folders of images, like an archivist of old.\n",
    "\n",
    "**Now there's Memery**.\n",
    "\n",
    "The `memery` package provides natural language search over local images. You can use it to search for things like \"a line drawing of a woman facing to the left\" and get _reasonably good results!_ \n",
    "\n",
    "You can do this over thousands of images (it's not optimized for performance yet, but search times scale well under O(n)). \n",
    "\n",
    "You can view the images in a browser GUI, or pipe them through command line tools. \n",
    "\n",
    "You can use `memery` or its modules in Jupyter notebooks, including GUI functions! \n",
    "\n",
    "Under the hood, `memery` makes use of **CLIP**, the [Contrastive Language-Image Pretraining transformer](https://github.com/openai/CLIP), released by OpenAI in 2021. CLIP trains a vision transformer and a language transformer to find the same latent space for images and their captions. This makes it perfect for the purpose of natural language image search. CLIP is a giant achievement, and `memery` stands on its shoulders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "- Usage\n",
    "  - Install locally\n",
    "  - Use GUI\n",
    "  - Use CLI\n",
    "  - Use in Jupyter\n",
    "  - Use the library\n",
    "- Development\n",
    "  - Notebook-driven development\n",
    "  - Pull the repo\n",
    "  - Branch and install\n",
    "  - Notebook-driven development\n",
    "  - Change the notebooks\n",
    "  - Test the notebooks\n",
    "  - Notebook-driven development\n",
    "  - Tangle the source code\n",
    "  - Weave the documentation\n",
    "- Contributing\n",
    "  - Who works on this project\n",
    "  - How you can help\n",
    "  - What we don't do\n",
    "  - Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "With Python 3.6 or greater:\n",
    "`pip install memery`\n",
    "\n",
    "Currently memery defaults to GPU installation. This will probably be switched in a future version. If you want to run CPU-only, run the following command after installing memery:\n",
    "\n",
    "`pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "Someday memery will be packaged in an easy to use format, but since this is a Python project it is hard to predict when that day will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "\n",
    "What's your use case? \n",
    "\n",
    "**I have images and want to search them with a GUI app**\n",
    "   \n",
    "   ↳  Use the Browser GUI\n",
    "   \n",
    "**i have a program/workflow and want to use image search as one part of it**\n",
    "  \n",
    "   ↳ Use in Jupyter\n",
    "   \n",
    "   ↳ Use as a Python module\n",
    "   \n",
    "   ↳ Use from command line or shell scripts\n",
    "   \n",
    "**i want to improve on and/or contribute to memery development**\n",
    " \n",
    "   ↳ Start by cloning the repo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GUI\n",
    "\n",
    "Currently memery has a rough browser-based GUI. To launch it, run the following in a command line: \n",
    "\n",
    "```memery serve```\n",
    "\n",
    "or set up a desktop shortcut that points to the above command.\n",
    "\n",
    "Memery will open in a browser window. The interface is pretty straightforward, but it has some quirks.\n",
    "\n",
    "![screenshot of memery GUI displaying wholesome memes](./images/streamlit-screenshot.png)\n",
    "\n",
    "The sidebar on the left controls the location and query for the search. The \"Directory\" box requires a full directory path; unfortunately, Streamlit does not yet have a folder-picker component. The path is relative to your current working directory when you run `memery serve`.\n",
    "\n",
    "The search will run once you enter a text or image query. If you enter both text and image queries, memery will search for the combination.\n",
    "\n",
    "Beneath these widgets is the output area for temporary messages displayed with each search. Mostly this can be ignored.\n",
    "\n",
    "The right hand panel displays the images and associated options. Major errors will appear here as giant stack traces; sometimes, changing variables in the other widgets will fix these errors live. If you get a large error here it's helpful to take a screenshot and share it with us in Github Issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use in Jupyter\n",
    "\n",
    "If you're in a Jupyter environment, you can summon an ipywidgets GUI directly into an output cell like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.gui import appPage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7170f06efa2849d586bc9b2d811b84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Box(children=(Text(value='images/', layout=Layout(max_width='80%'), placeholder='path/to/i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<memery.gui.appPage at 0x7f829c87d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = appPage()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot of memery Jupyter GUI displaying wholesome memes](./images/jupyter-screenshot.png)\n",
    "\n",
    "Unfortunately the widgets won't display without an active runtime, so the above is a screenshot. In a Jupyter environment, the GUI works just like the browser-based GUI. \n",
    "\n",
    "Opening new appPage instances in separate cells can be helpful for exploring a dataset, but it can also cause memory overruns. For this reason the Jupyter interface is tabbed and each search will appear in a new tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CLI\n",
    "\n",
    "The memery command line is currently very rudimentary. So far you can use `memery` on any folder and it will search for images recursively, returning a list object to stdout. \n",
    "\n",
    "Pass the --n flag to control how many images are returned (default 10).\n",
    "\n",
    "`memery recall PATH/TO/IMAGE/FOLDER 'query' --n 20`\n",
    "\n",
    "I'm not clear yet on what behavior command-line users will expect from it. In the future we may want to make it non-recursive by default, and map the behavior more closely to POSIX standards. I would love feedback or help on this.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function currently called `queryFlow` (against all Python convention) accepts a folder name and a query and returns a ranked list of image files. This is also recursive by default, and prints too much information into stdout. And it calls indexFlow every time, which can be annoying if you have corrupted files in the directory, as it will need to rebuild the tree-index each time despite the files not changing. This will be solved in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.core import queryFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 44503.23it/s]\n",
      "89it [00:00, 37660.72it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting timer\n",
      "Checking files\n",
      "Indexing\n",
      "Skipping bad file: images/memes/corrupted-file.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n",
      "Skipping bad file: images/memes/.ipynb_checkpoints/corrupted-file-checkpoint.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n",
      "Loaded 82 encodings\n",
      "Encoding 0 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 82 encodings\n",
      "Converting query\n",
      "Searching 82 images\n",
      "Done in 0.5853581428527832 seconds\n",
      "['images/memes/Wholesome-Meme-68.jpg', 'images/memes/Wholesome-Meme-74.jpg', 'images/memes/Wholesome-Meme-88.jpg', 'images/memes/Wholesome-Meme-78.jpg', 'images/memes/Wholesome-Meme-23.jpg']\n"
     ]
    }
   ],
   "source": [
    "ranked = queryFlow('./images', 'dad joke')\n",
    "\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Okay, now we need a whole part about development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Compile this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_loader.ipynb.\n",
      "Converted 02_crafter.ipynb.\n",
      "Converted 03_encoder.ipynb.\n",
      "Converted 04_indexer.ipynb.\n",
      "Converted 05_ranker.ipynb.\n",
      "Converted 06_fileutils.ipynb.\n",
      "Converted 07_cli.ipynb.\n",
      "Converted 08_jupyter_gui.ipynb.\n",
      "Converted 09_streamlit_app.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
