{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# memery\n",
    "\n",
    "> Search over large image datasets with natural language and computer vision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![meme about having too many memes](images/E2GoeMyWEAAkcLz.jpeg)\n",
    "\n",
    "You know the problem. You have a huge folder of images: memes, screenshots, datasets, product photos, inspo albums, anything. You know that somewhere in that folder is the exact image you want, but you can't remember the filename or what day you saved it. There's nothing you can do. You have to scroll through the folder, skimming hundreds of thumbnails, hoping you don't accidentally miss it, hoping you'll recognize it when you do see it. And amazingly, humans can do this pretty well! But local image search is still pretty much a manual effort - you're still sorting through folders of images, like an archivist of old. Computers haven't made it much easier.\n",
    "\n",
    "Until now.\n",
    "\n",
    "The `memery` package provides natural language search over local images. You can use it to search for things like \"a line drawing of a woman facing to the left\" and get _reasonably good results!_ \n",
    "\n",
    "You can do this over thousands of images (it's not optimized for performance yet, but search times seem to scale well). \n",
    "\n",
    "You can view the images in a browser GUI, or pipe them through command line tools. \n",
    "\n",
    "You can use `memery` or its modules in Jupyter notebooks, including GUI functions! \n",
    "\n",
    "Under the hood, `memery` makes use of **CLIP**, the [Contrastive Language-Image Pretraining transformer](https://github.com/openai/CLIP), released by OpenAI in 2021. CLIP trains a vision transformer and a language transformer to find the same latent space for images and their captions. This makes it perfect for the purpose of natural language image search. CLIP is a giant achievement, and `memery` stands on its shoulders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "The necessary CLIP and torch packages will be installed by pip. You might want to make sure you have a sane CUDA environment before and after this step if you're trying to use GPU. If you don't have a GPU, `memery` should still work on your CPU. \n",
    "\n",
    "If you have any trouble please **open an issue on Github**! I want to make this package useful for as many people as possible. Help me know what's going wrong :)\n",
    "\n",
    "`pip install memery`\n",
    "\n",
    "If you don't have a GPU for PyTorch, this command might help\n",
    "    \n",
    "`pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GUI\n",
    "\n",
    "The browser GUI is a Streamlit app. You can run it from the command line with \n",
    "\n",
    "`memery serve`\n",
    "\n",
    "or set up a desktop shortcut to use it from your menu.\n",
    "\n",
    "If you're in a Jupyter environment, you can summon the GUI directly into an output cell like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.gui import appPage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166b1901033c4fe68af1a75fc4a9e71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Box(children=(Text(value='images/', layout=Layout(max_width='80%'), placeholder='path/to/iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<memery.gui.appPage at 0x7f6c0e7c80d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = appPage()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CLI\n",
    "\n",
    "From the command line, you can use `memery` on any folder and it will search for images recursively, returning a list object to stdout.\n",
    "\n",
    "Pass the --n flag to control how many images are returned (default 10).\n",
    "\n",
    "`memery recall PATH/TO/IMAGE/FOLDER 'query' --n 20\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply use `queryFlow` to search over a folder recursively! The folder will be indexed, if an index doesn't already exist. Then any new images will be CLIP-encoded, an Annoy treemap built, and a list of ranked filenames returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.core import queryFlow\n",
    "from memery.gui import get_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = queryFlow('./images', 'dad joke')\n",
    "\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Compile this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_loader.ipynb.\n",
      "Converted 02_crafter.ipynb.\n",
      "Converted 03_encoder.ipynb.\n",
      "Converted 04_indexer.ipynb.\n",
      "Converted 05_ranker.ipynb.\n",
      "Converted 06_fileutils.ipynb.\n",
      "Converted 07_cli.ipynb.\n",
      "Converted 08_jupyter_gui.ipynb.\n",
      "Converted 09_streamlit_app.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
