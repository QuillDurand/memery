{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "Find the meme you are looking for!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the core module, which loads the CLIP model and the encodings of all the images in the folder, then tokenizes the search text or image, and finally returns a sorted list of filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular flow system\n",
    "\n",
    "I'm using the Neural Search design pattern as described by Han Xiao in e.g. [General Neural Elastic Search and Go Way Beyond](https://hanxiao.io/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond)&c.\n",
    "\n",
    "This is a system designed to be scalable and distributed if necessary. Even for a single-machine scenario, I like the functional style of it: grab data, transform it and pass it downstream, all the way from the folder to the output widget.\n",
    "\n",
    "There are two main types of operater in neural search: **flows** and **executors**.\n",
    "\n",
    "**Flows** are specific patterns of data manipulation and storage. **Executors** are the operators that transform the data within the flow. \n",
    "\n",
    "There are two core flows to any search system: indexing, and querying. The plan here is to make executors that can be composed into flows and then compose the flows into a UI that supports querying and, to some extent, indexing as well.\n",
    "\n",
    "The core executors for this use case are:\n",
    " - Loader\n",
    " - Crafter\n",
    " - Encoder\n",
    " - Indexer\n",
    " - Ranker\n",
    " - Gateway\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gateway Process -- not yet implemented**\n",
    "\n",
    "Takes a query and processes it through either Indexing Flow or Querying Flow, passing along arguments. The main entrypoint for each iteration of the index/query process.\n",
    "\n",
    "Querying Flow can technically process either text or image search, becuase the CLIP encoder will put them into the same embedding space. So we might as well build in a method for either, and make it available to the user, since it's impressive and useful and relatively easy to build. \n",
    "\n",
    "Eventually the Gateway process probably needs to be quite complicated, for serving all the different users and for delivering REST APIs to different clients. We'll need a way to accept text and images as HTTP requests and return JSON dictionaries (especially at the encoder, which will remain server-bound more than any other executor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "For now, calling the `queryFlow` process directly is the simplest gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from memery.loader import get_image_files, archive_loader, db_loader, treemap_loader \n",
    "from memery.crafter import crafter\n",
    "from memery.encoder import image_encoder, text_encoder\n",
    "from memery.indexer import join_all, build_treemap, save_archives\n",
    "from memery.ranker import ranker, nns_to_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `indexFlow` checks the local directory for files with image extensions, loads the archive, splits out any new images to be encoded and encodes them, then finally builds a treemap and saves it along with the new archive. It returns a tuple with the locations of the archive and treemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def indexFlow(path):\n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    filepaths = get_image_files(root)\n",
    "    archive_db = {}\n",
    "    \n",
    "    archive_db, new_files = archive_loader(filepaths, root, device)\n",
    "    print(f\"Loaded {len(archive_db)} encodings\")\n",
    "    print(f\"Encoding {len(new_files)} new images\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    crafted_files = crafter(new_files, device)\n",
    "    new_embeddings = image_encoder(crafted_files, device)\n",
    "    \n",
    "    db = join_all(archive_db, new_files, new_embeddings)\n",
    "    print(\"Building treemap\")\n",
    "    t = build_treemap(db)\n",
    "    \n",
    "    print(f\"Saving {len(db)}images\")\n",
    "    save_paths = save_archives(root, t, db)\n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(save_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the current savefile for testing purposes\n",
    "Path('images/memery.pt').unlink()\n",
    "Path('images/memery.ann').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 encodings\n",
      "Encoding 80 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n",
      "Saving 80images\n",
      "Done in 1.3616180259996327 seconds\n"
     ]
    }
   ],
   "source": [
    "save_paths = indexFlow('./images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/memery.pt', 'images/memery.ann')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert save_paths\n",
    "save_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `queryFlow` takes a path and a query, checks for an index, loads it and searches through the treemap if it exists, and calls `indexFlow` to index it first if it hasn't been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def queryFlow(path, query): \n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    dbpath = root/'memery.pt'\n",
    "    db = db_loader(dbpath, device)\n",
    "    treepath = root/'memery.ann'\n",
    "    treemap = treemap_loader(treepath)\n",
    "    \n",
    "    filepaths = get_image_files(root)\n",
    "    if treemap == None or len(db) != len(filepaths):\n",
    "        dbpath, treepath = indexFlow(root)\n",
    "        treemap = treemap_loader(Path(treepath))\n",
    "        db = db_loader(dbpath, device)\n",
    "    \n",
    "    print(f\"Searching {len(db)} images\")\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    query_vec = text_encoder(query, device)\n",
    "    indexes = ranker(query_vec, treemap)\n",
    "    ranked_files = nns_to_files(db, indexes)\n",
    "    \n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(ranked_files)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just a helper function to print images in a notebook:\n",
    "\n",
    "from memery.gui import get_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './images'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 80 images\n",
      "Done in 0.01216482800009544 seconds\n"
     ]
    }
   ],
   "source": [
    "ranked = queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/Wholesome-Meme-8.jpg',\n",
       " 'images/Wholesome-Meme-5.jpg',\n",
       " 'images/Wholesome-Meme-35.jpg',\n",
       " 'images/Wholesome-Meme-67.png',\n",
       " 'images/embarassed-dog-on-bed-SA2BDZW.jpg',\n",
       " 'images/Wholesome-Meme-72.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34c61d1765b498e8ccb7cd0bdf0a81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xe2\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_grid(ranked, n=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
