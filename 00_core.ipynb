{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "Find the meme you are looking for!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the core module, which loads the CLIP model and the encodings of all the images in the folder, then tokenizes the search text or image, and finally returns a sorted list of filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular flow system\n",
    "\n",
    "I'm using the Neural Search design pattern as described by Han Xiao in e.g. [General Neural Elastic Search and Go Way Beyond](https://hanxiao.io/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond)&c.\n",
    "\n",
    "This is a system designed to be scalable and distributed if necessary. Even for a single-machine scenario, I like the functional style of it: grab data, transform it and pass it downstream, all the way from the folder to the output widget.\n",
    "\n",
    "There are two main types of operater in neural search: **flows** and **executors**.\n",
    "\n",
    "**Flows** are specific patterns of data manipulation and storage. **Executors** are the operators that transform the data within the flow. \n",
    "\n",
    "There are two core flows to any search system: indexing, and querying. The plan here is to make executors that can be composed into flows and then compose the flows into a UI that supports querying and, to some extent, indexing as well.\n",
    "\n",
    "The core executors for this use case are:\n",
    " - Loader\n",
    " - Crafter\n",
    " - Encoder\n",
    " - Indexer\n",
    " - Ranker\n",
    " - Gateway\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gateway Process -- not yet implemented**\n",
    "\n",
    "Takes a query and processes it through either Indexing Flow or Querying Flow, passing along arguments. The main entrypoint for each iteration of the index/query process.\n",
    "\n",
    "Querying Flow can technically process either text or image search, becuase the CLIP encoder will put them into the same embedding space. So we might as well build in a method for either, and make it available to the user, since it's impressive and useful and relatively easy to build. \n",
    "\n",
    "Eventually the Gateway process probably needs to be quite complicated, for serving all the different users and for delivering REST APIs to different clients. We'll need a way to accept text and images as HTTP requests and return JSON dictionaries (especially at the encoder, which will remain server-bound more than any other executor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "For now, calling the `queryFlow` process directly is the simplest gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from memery.loader import get_image_files, archive_loader, db_loader, treemap_loader \n",
    "from memery.crafter import crafter\n",
    "from memery.encoder import image_encoder, text_encoder\n",
    "from memery.indexer import join_all, build_treemap, save_archives\n",
    "from memery.ranker import ranker, nns_to_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `indexFlow` checks the local directory for files with image extensions, loads the archive, splits out any new images to be encoded and encodes them, then finally builds a treemap and saves it along with the new archive. It returns a tuple with the locations of the archive and treemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def indexFlow(path):\n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    filepaths = get_image_files(root)\n",
    "    archive_db = {}\n",
    "    \n",
    "    archive_db, new_files = archive_loader(filepaths, root, device)\n",
    "    print(f\"Loaded {len(archive_db)} encodings\")\n",
    "    print(f\"Encoding {len(new_files)} new images\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    crafted_files = crafter(new_files, device)\n",
    "    new_embeddings = image_encoder(crafted_files, device)\n",
    "    \n",
    "    db = join_all(archive_db, new_files, new_embeddings)\n",
    "    print(\"Building treemap\")\n",
    "    t = build_treemap(db)\n",
    "    \n",
    "    print(f\"Saving {len(db)}images\")\n",
    "    save_paths = save_archives(root, t, db)\n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(save_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the current savefile for testing purposes\n",
    "Path('images/memery.pt').unlink()\n",
    "Path('images/memery.ann').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 encodings\n",
      "Encoding 80 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n",
      "Saving 79images\n",
      "Done in 1.381443322999985 seconds\n"
     ]
    }
   ],
   "source": [
    "save_paths = indexFlow('./images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/memery.pt', 'images/memery.ann')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert save_paths\n",
    "save_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `queryFlow` takes a path and a query, checks for an index, loads it and searches through the treemap if it exists, and calls `indexFlow` to index it first if it hasn't been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def queryFlow(path, query): \n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    dbpath = root/'memery.pt'\n",
    "    db = db_loader(dbpath, device)\n",
    "    treepath = root/'memery.ann'\n",
    "    treemap = treemap_loader(treepath)\n",
    "    \n",
    "    if treemap == None or db == {}:\n",
    "        dbpath, treepath = indexFlow(root)\n",
    "        treemap = treemap_loader(Path(treepath))\n",
    "        db = db_loader(dbpath, device)\n",
    "    \n",
    "    print(f\"Searching {len(db)} images\")\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    query_vec = text_encoder(query, device)\n",
    "    indexes = ranker(query_vec, treemap)\n",
    "    ranked_files = nns_to_files(db, indexes)\n",
    "    \n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(ranked_files)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just a helper function to print images in a notebook:\n",
    "\n",
    "from memery.gui import get_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './images'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 79 images\n",
      "Done in 0.08653578300072695 seconds\n"
     ]
    }
   ],
   "source": [
    "ranked = queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/Wholesome-Meme-8.jpg',\n",
       " 'images/Wholesome-Meme-5.jpg',\n",
       " 'images/Wholesome-Meme-35.jpg',\n",
       " 'images/Wholesome-Meme-67.png',\n",
       " 'images/embarassed-dog-on-bed-SA2BDZW.jpg',\n",
       " 'images/Wholesome-Meme-72.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1e22cb82a84ee8a700ab61e3ff2397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xe2\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_grid(ranked, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_Working out the timing issues in flow_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/mage/Pictures/memes/Pixel/Pictures/'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 367 images\n",
      "Done in 0.03215723000175785 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.059621 s\n",
       "File: <ipython-input-8-f0ea29459e86>\n",
       "Function: queryFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def queryFlow(path, query): \n",
       "     3         1         83.0     83.0      0.1      root = Path(path)\n",
       "     4         1         51.0     51.0      0.1      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1         42.0     42.0      0.1      dbpath = root/'memery.pt'\n",
       "     7         1      26706.0  26706.0     44.8      db = db_loader(dbpath, device)\n",
       "     8         1         36.0     36.0      0.1      treepath = root/'memery.ann'\n",
       "     9         1        413.0    413.0      0.7      treemap = treemap_loader(treepath)\n",
       "    10                                               \n",
       "    11         1          2.0      2.0      0.0      if treemap == None or db == {}:\n",
       "    12                                                   dbpath, treepath = indexFlow(root)\n",
       "    13                                                   treemap = treemap_loader(Path(treepath))\n",
       "    14                                                   db = db_loader(dbpath, device)\n",
       "    15                                               \n",
       "    16         1         79.0     79.0      0.1      print(f\"Searching {len(db)} images\")\n",
       "    17         1          2.0      2.0      0.0      start_time = time.perf_counter()\n",
       "    18                                               \n",
       "    19         1       6580.0   6580.0     11.0      query_vec = text_encoder(query, device)\n",
       "    20         1       7535.0   7535.0     12.6      indexes = ranker(query_vec, treemap)\n",
       "    21         1      18008.0  18008.0     30.2      ranked_files = nns_to_files(db, indexes)\n",
       "    22                                               \n",
       "    23         1         83.0     83.0      0.1      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    24                                               \n",
       "    25         1          1.0      1.0      0.0      return(ranked_files)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f queryFlow queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 367 encodings\n",
      "Encoding 0 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 367images\n",
      "Done in 1.8026166210001975 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 1.85444 s\n",
       "File: <ipython-input-4-3f277edb55d4>\n",
       "Function: indexFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def indexFlow(path):\n",
       "     3         1         38.0     38.0      0.0      root = Path(path)\n",
       "     4         1         30.0     30.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1      16144.0  16144.0      0.9      filepaths = get_image_files(root)\n",
       "     7         1          2.0      2.0      0.0      archive_db = {}\n",
       "     8                                               \n",
       "     9         1      35290.0  35290.0      1.9      archive_db, new_files = archive_loader(filepaths, root, device)\n",
       "    10         1        189.0    189.0      0.0      print(f\"Loaded {len(archive_db)} encodings\")\n",
       "    11         1         55.0     55.0      0.0      print(f\"Encoding {len(new_files)} new images\")\n",
       "    12                                           \n",
       "    13         1          3.0      3.0      0.0      start_time = time.perf_counter()\n",
       "    14                                           \n",
       "    15         1        495.0    495.0      0.0      crafted_files = crafter(new_files, device)\n",
       "    16         1     110210.0 110210.0      5.9      new_embeddings = image_encoder(crafted_files, device)\n",
       "    17                                               \n",
       "    18         1          8.0      8.0      0.0      db = join_all(archive_db, new_files, new_embeddings)\n",
       "    19         1         45.0     45.0      0.0      print(\"Building treemap\")\n",
       "    20         1    1676026.0 1676026.0     90.4      t = build_treemap(db)\n",
       "    21                                               \n",
       "    22         1         76.0     76.0      0.0      print(f\"Saving {len(db)}images\")\n",
       "    23         1      15740.0  15740.0      0.8      save_paths = save_archives(root, t, db)\n",
       "    24         1         85.0     85.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    25                                               \n",
       "    26         1          1.0      1.0      0.0      return(save_paths)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f indexFlow indexFlow(Path(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/mage/Pictures/occult-imagery/'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 26722 images\n",
      "Done in 95.6256318759988 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 96.3339 s\n",
       "File: <ipython-input-8-f0ea29459e86>\n",
       "Function: queryFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def queryFlow(path, query): \n",
       "     3         1         52.0     52.0      0.0      root = Path(path)\n",
       "     4         1         37.0     37.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1         28.0     28.0      0.0      dbpath = root/'memery.pt'\n",
       "     7         1     707512.0 707512.0      0.7      db = db_loader(dbpath, device)\n",
       "     8         1         30.0     30.0      0.0      treepath = root/'memery.ann'\n",
       "     9         1        457.0    457.0      0.0      treemap = treemap_loader(treepath)\n",
       "    10                                               \n",
       "    11         1          1.0      1.0      0.0      if treemap == None or db == {}:\n",
       "    12                                                   dbpath, treepath = indexFlow(root)\n",
       "    13                                                   treemap = treemap_loader(Path(treepath))\n",
       "    14                                                   db = db_loader(dbpath, device)\n",
       "    15                                               \n",
       "    16         1         67.0     67.0      0.0      print(f\"Searching {len(db)} images\")\n",
       "    17         1          1.0      1.0      0.0      start_time = time.perf_counter()\n",
       "    18                                               \n",
       "    19         1       4572.0   4572.0      0.0      query_vec = text_encoder(query, device)\n",
       "    20         1     102501.0 102501.0      0.1      indexes = ranker(query_vec, treemap)\n",
       "    21         1   95518545.0 95518545.0     99.2      ranked_files = nns_to_files(db, indexes)\n",
       "    22                                               \n",
       "    23         1         85.0     85.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    24                                               \n",
       "    25         1          0.0      0.0      0.0      return(ranked_files)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f queryFlow queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26722 encodings\n",
      "Encoding 0 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 26722images\n",
      "Done in 122.27596841900231 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 132.016 s\n",
       "File: <ipython-input-4-3f277edb55d4>\n",
       "Function: indexFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def indexFlow(path):\n",
       "     3         1         19.0     19.0      0.0      root = Path(path)\n",
       "     4         1         17.0     17.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1     844439.0 844439.0      0.6      filepaths = get_image_files(root)\n",
       "     7         1          2.0      2.0      0.0      archive_db = {}\n",
       "     8                                               \n",
       "     9         1    8895508.0 8895508.0      6.7      archive_db, new_files = archive_loader(filepaths, root, device)\n",
       "    10         1         94.0     94.0      0.0      print(f\"Loaded {len(archive_db)} encodings\")\n",
       "    11         1         21.0     21.0      0.0      print(f\"Encoding {len(new_files)} new images\")\n",
       "    12                                           \n",
       "    13         1          2.0      2.0      0.0      start_time = time.perf_counter()\n",
       "    14                                           \n",
       "    15         1        261.0    261.0      0.0      crafted_files = crafter(new_files, device)\n",
       "    16         1     114964.0 114964.0      0.1      new_embeddings = image_encoder(crafted_files, device)\n",
       "    17                                               \n",
       "    18         1          8.0      8.0      0.0      db = join_all(archive_db, new_files, new_embeddings)\n",
       "    19         1         45.0     45.0      0.0      print(\"Building treemap\")\n",
       "    20         1  120994854.0 120994854.0     91.7      t = build_treemap(db)\n",
       "    21                                               \n",
       "    22         1         86.0     86.0      0.0      print(f\"Saving {len(db)}images\")\n",
       "    23         1    1165733.0 1165733.0      0.9      save_paths = save_archives(root, t, db)\n",
       "    24         1         88.0     88.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    25                                               \n",
       "    26         1          0.0      0.0      0.0      return(save_paths)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f indexFlow indexFlow(Path(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
