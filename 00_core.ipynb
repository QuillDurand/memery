{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "Find the meme you are looking for!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the core module, which loads the CLIP model and the encodings of all the images in the folder, then tokenizes the search text or image, and finally returns a sorted list of filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular flow system\n",
    "\n",
    "I'm using the Neural Search design pattern as described by Han Xiao in e.g. [General Neural Elastic Search and Go Way Beyond](https://hanxiao.io/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond)&c.\n",
    "\n",
    "This is a system designed to be scalable and distributed if necessary. Even for a single-machine scenario, I like the functional style of it: grab data, transform it and pass it downstream, all the way from the folder to the output widget.\n",
    "\n",
    "There are two main types of operater in neural search: **flows** and **executors**.\n",
    "\n",
    "**Flows** are specific patterns of data manipulation and storage. **Executors** are the operators that transform the data within the flow. \n",
    "\n",
    "There are two core flows to any search system: indexing, and querying. The plan here is to make executors that can be composed into flows and then compose the flows into a UI that supports querying and, to some extent, indexing as well.\n",
    "\n",
    "The core executors for this use case are:\n",
    " - Loader\n",
    " - Crafter\n",
    " - Encoder\n",
    " - Indexer\n",
    " - Ranker\n",
    " - Gateway\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gateway Process -- not yet implemented**\n",
    "\n",
    "Takes a query and processes it through either Indexing Flow or Querying Flow, passing along arguments. The main entrypoint for each iteration of the index/query process.\n",
    "\n",
    "Querying Flow can technically process either text or image search, becuase the CLIP encoder will put them into the same embedding space. So we might as well build in a method for either, and make it available to the user, since it's impressive and useful and relatively easy to build. \n",
    "\n",
    "Eventually the Gateway process probably needs to be quite complicated, for serving all the different users and for delivering REST APIs to different clients. We'll need a way to accept text and images as HTTP requests and return JSON dictionaries (especially at the encoder, which will remain server-bound more than any other executor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "For now, calling the `queryFlow` process directly is the simplest gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from memery.loader import get_image_files, archive_loader, db_loader, treemap_loader \n",
    "from memery.crafter import crafter\n",
    "from memery.encoder import image_encoder, text_encoder\n",
    "from memery.indexer import join_all, build_treemap, save_archives\n",
    "from memery.ranker import ranker, nns_to_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `indexFlow` checks the local directory for files with image extensions, loads the archive, splits out any new images to be encoded and encodes them, then finally builds a treemap and saves it along with the new archive. It returns a tuple with the locations of the archive and treemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def indexFlow(path):\n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    filepaths = get_image_files(root)\n",
    "    archive_db = {}\n",
    "    \n",
    "    archive_db, new_files = archive_loader(filepaths, root, device)\n",
    "    print(f\"Loaded {len(archive_db)} encodings\")\n",
    "    print(f\"Encoding {len(new_files)} new images\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    crafted_files = crafter(new_files, device)\n",
    "    new_embeddings = image_encoder(crafted_files, device)\n",
    "    \n",
    "    db = join_all(archive_db, new_files, new_embeddings)\n",
    "    print(\"Building treemap\")\n",
    "    t = build_treemap(db)\n",
    "    \n",
    "    print(f\"Saving {len(db)}images\")\n",
    "    save_paths = save_archives(root, t, db)\n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(save_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the current savefile for testing purposes\n",
    "Path('images/memery.pt').unlink()\n",
    "Path('images/memery.ann').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 encodings\n",
      "Encoding 80 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n",
      "Saving 79images\n",
      "Done in 1.4366280770045705 seconds\n"
     ]
    }
   ],
   "source": [
    "save_paths = indexFlow('./images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('images/memery.pt', 'images/memery.ann')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert save_paths\n",
    "save_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `queryFlow` takes a path and a query, checks for an index, loads it and searches through the treemap if it exists, and calls `indexFlow` to index it first if it hasn't been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def queryFlow(path, query): \n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    dbpath = root/'memery.pt'\n",
    "    db = db_loader(dbpath, device)\n",
    "    treepath = root/'memery.ann'\n",
    "    treemap = treemap_loader(treepath)\n",
    "    \n",
    "    if treemap == None or db == {}:\n",
    "        dbpath, treepath = indexFlow(root)\n",
    "        treemap = treemap_loader(Path(treepath))\n",
    "        db = db_loader(dbpath, device)\n",
    "    \n",
    "    print(f\"Searching {len(db)} images\")\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    query_vec = text_encoder(query, device)\n",
    "    indexes = ranker(query_vec, treemap)\n",
    "    ranked_files = nns_to_files(db, indexes)\n",
    "    \n",
    "    print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
    "    \n",
    "    return(ranked_files)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just a helper function to print images in a notebook:\n",
    "\n",
    "from memery.gui import get_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './images'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 79 images\n",
      "Done in 0.0929578750001383 seconds\n"
     ]
    }
   ],
   "source": [
    "ranked = queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/Wholesome-Meme-8.jpg',\n",
       " 'images/Wholesome-Meme-5.jpg',\n",
       " 'images/Wholesome-Meme-35.jpg',\n",
       " 'images/Wholesome-Meme-67.png',\n",
       " 'images/embarassed-dog-on-bed-SA2BDZW.jpg',\n",
       " 'images/Wholesome-Meme-72.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdcc15aaaf44419ae334627becb06a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xe2\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_grid(ranked, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_Working out the timing issues in flow_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/mage/Pictures/memes/Pixel/Pictures/'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the current savefile for testing purposes\n",
    "# Path(f'{root}memery.pt').unlink()\n",
    "# Path(f'{root}memery.ann').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 encodings\n",
      "Encoding 1303 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [00:06<00:07,  1.21s/it]/home/mage/.local/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n",
      "Saving 1303images\n",
      "Done in 18.440638860003673 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 18.4743 s\n",
       "File: <ipython-input-4-3f277edb55d4>\n",
       "Function: indexFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def indexFlow(path):\n",
       "     3         1         23.0     23.0      0.0      root = Path(path)\n",
       "     4         1         25.0     25.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1      32341.0  32341.0      0.2      filepaths = get_image_files(root)\n",
       "     7         1          1.0      1.0      0.0      archive_db = {}\n",
       "     8                                               \n",
       "     9         1       1104.0   1104.0      0.0      archive_db, new_files = archive_loader(filepaths, root, device)\n",
       "    10         1         97.0     97.0      0.0      print(f\"Loaded {len(archive_db)} encodings\")\n",
       "    11         1         23.0     23.0      0.0      print(f\"Encoding {len(new_files)} new images\")\n",
       "    12                                           \n",
       "    13         1          3.0      3.0      0.0      start_time = time.perf_counter()\n",
       "    14                                           \n",
       "    15         1       1355.0   1355.0      0.0      crafted_files = crafter(new_files, device)\n",
       "    16         1   12170313.0 12170313.0     65.9      new_embeddings = image_encoder(crafted_files, device)\n",
       "    17                                               \n",
       "    18         1       3817.0   3817.0      0.0      db = join_all(archive_db, new_files, new_embeddings)\n",
       "    19         1         82.0     82.0      0.0      print(\"Building treemap\")\n",
       "    20         1    6216161.0 6216161.0     33.6      t = build_treemap(db)\n",
       "    21                                               \n",
       "    22         1         74.0     74.0      0.0      print(f\"Saving {len(db)}images\")\n",
       "    23         1      48820.0  48820.0      0.3      save_paths = save_archives(root, t, db)\n",
       "    24         1         69.0     69.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    25                                               \n",
       "    26         1          1.0      1.0      0.0      return(save_paths)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f indexFlow indexFlow(Path(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 1303 images\n",
      "Done in 0.21823624199896585 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.248458 s\n",
       "File: <ipython-input-8-f0ea29459e86>\n",
       "Function: queryFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def queryFlow(path, query): \n",
       "     3         1         76.0     76.0      0.0      root = Path(path)\n",
       "     4         1         24.0     24.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1         15.0     15.0      0.0      dbpath = root/'memery.pt'\n",
       "     7         1      29851.0  29851.0     12.0      db = db_loader(dbpath, device)\n",
       "     8         1         38.0     38.0      0.0      treepath = root/'memery.ann'\n",
       "     9         1         51.0     51.0      0.0      treemap = treemap_loader(treepath)\n",
       "    10                                               \n",
       "    11         1          1.0      1.0      0.0      if treemap == None or db == {}:\n",
       "    12                                                   dbpath, treepath = indexFlow(root)\n",
       "    13                                                   treemap = treemap_loader(Path(treepath))\n",
       "    14                                                   db = db_loader(dbpath, device)\n",
       "    15                                               \n",
       "    16         1         99.0     99.0      0.0      print(f\"Searching {len(db)} images\")\n",
       "    17         1          2.0      2.0      0.0      start_time = time.perf_counter()\n",
       "    18                                               \n",
       "    19         1       5823.0   5823.0      2.3      query_vec = text_encoder(query, device)\n",
       "    20         1       5887.0   5887.0      2.4      indexes = ranker(query_vec, treemap)\n",
       "    21         1     206516.0 206516.0     83.1      ranked_files = nns_to_files(db, indexes)\n",
       "    22                                               \n",
       "    23         1         74.0     74.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    24                                               \n",
       "    25         1          1.0      1.0      0.0      return(ranked_files)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f queryFlow queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/mage/Pictures/occult-imagery/'\n",
    "query = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 26722 images\n",
      "Done in 96.83730196499528 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 97.4745 s\n",
       "File: <ipython-input-8-f0ea29459e86>\n",
       "Function: queryFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def queryFlow(path, query): \n",
       "     3         1         31.0     31.0      0.0      root = Path(path)\n",
       "     4         1         23.0     23.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1         16.0     16.0      0.0      dbpath = root/'memery.pt'\n",
       "     7         1     635653.0 635653.0      0.7      db = db_loader(dbpath, device)\n",
       "     8         1         28.0     28.0      0.0      treepath = root/'memery.ann'\n",
       "     9         1        999.0    999.0      0.0      treemap = treemap_loader(treepath)\n",
       "    10                                               \n",
       "    11         1          2.0      2.0      0.0      if treemap == None or db == {}:\n",
       "    12                                                   dbpath, treepath = indexFlow(root)\n",
       "    13                                                   treemap = treemap_loader(Path(treepath))\n",
       "    14                                                   db = db_loader(dbpath, device)\n",
       "    15                                               \n",
       "    16         1        387.0    387.0      0.0      print(f\"Searching {len(db)} images\")\n",
       "    17         1          1.0      1.0      0.0      start_time = time.perf_counter()\n",
       "    18                                               \n",
       "    19         1       4578.0   4578.0      0.0      query_vec = text_encoder(query, device)\n",
       "    20         1     100370.0 100370.0      0.1      indexes = ranker(query_vec, treemap)\n",
       "    21         1   96732340.0 96732340.0     99.2      ranked_files = nns_to_files(db, indexes)\n",
       "    22                                               \n",
       "    23         1        116.0    116.0      0.0      print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    24                                               \n",
       "    25         1          0.0      0.0      0.0      return(ranked_files)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f queryFlow queryFlow(root, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26722 encodings\n",
      "Encoding 0 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 11.8187 s\n",
       "File: <ipython-input-4-3f277edb55d4>\n",
       "Function: indexFlow at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def indexFlow(path):\n",
       "     3         1         19.0     19.0      0.0      root = Path(path)\n",
       "     4         1         18.0     18.0      0.0      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "     5                                               \n",
       "     6         1    1228368.0 1228368.0     10.4      filepaths = get_image_files(root)\n",
       "     7         1          2.0      2.0      0.0      archive_db = {}\n",
       "     8                                               \n",
       "     9         1    9014579.0 9014579.0     76.3      archive_db, new_files = archive_loader(filepaths, root, device)\n",
       "    10         1         83.0     83.0      0.0      print(f\"Loaded {len(archive_db)} encodings\")\n",
       "    11         1         21.0     21.0      0.0      print(f\"Encoding {len(new_files)} new images\")\n",
       "    12                                           \n",
       "    13         1          2.0      2.0      0.0      start_time = time.perf_counter()\n",
       "    14                                           \n",
       "    15         1        334.0    334.0      0.0      crafted_files = crafter(new_files, device)\n",
       "    16         1     116654.0 116654.0      1.0      new_embeddings = image_encoder(crafted_files, device)\n",
       "    17                                               \n",
       "    18         1          9.0      9.0      0.0      db = join_all(archive_db, new_files, new_embeddings)\n",
       "    19         1         43.0     43.0      0.0      print(\"Building treemap\")\n",
       "    20         1    1458594.0 1458594.0     12.3      t = build_treemap(db)\n",
       "    21                                               \n",
       "    22                                               print(f\"Saving {len(db)}images\")\n",
       "    23                                               save_paths = save_archives(root, t, db)\n",
       "    24                                               print(f\"Done in {time.perf_counter() - start_time} seconds\")\n",
       "    25                                               \n",
       "    26                                               return(save_paths)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f indexFlow indexFlow(Path(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
