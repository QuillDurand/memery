{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from milvus import Milvus, IndexType, MetricType, Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus = Milvus(host='localhost', port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message='Create collection successfully!')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milvus.create_collection({\n",
    "    'collection_name': 'memes_small',\n",
    "    'dimension': 512\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import clip\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as Img, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set torch ðŸ”¦ device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# load CLIP ðŸ“Ž model\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)\n",
    "logit_scale = model.logit_scale.exp()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_images(path):\n",
    "    '''Batch process images with CLIP and return their feature embeddings'''\n",
    "    image_features = torch.tensor(()).to(device)\n",
    "    with torch.no_grad():\n",
    "        imagefiles=torchvision.datasets.ImageFolder(root=path, transform=preprocess)\n",
    "        img_loader=torch.utils.data.DataLoader(imagefiles, batch_size=128, shuffle=False, num_workers=4)\n",
    "        for images, labels in tqdm(img_loader):\n",
    "            batch_features = model.encode_image(images)\n",
    "            image_features = torch.cat((image_features, batch_features)).to(device)\n",
    "\n",
    "    image_names = [Path(f[0]) for f in imagefiles.imgs]\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return(image_names, image_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "image_names, image_features = preproc_images(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a lot of research, I found I don't want to use Milvus because it can't operate on ARM devices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
